---
title: "BEST Primary Analysis"
subtitle: "ELC Discussion"
author: "John Sperger"
date: "2024-06-12"
always_allow_html: true
format:
  beamer:
    pdf-engine: lualatex
    classoption: professionalfonts, math-style=TeX, spacing = French
    aspectratio: 169
    slide-level: 3
    toc: true
    toc-location: left
    toc-depth: 2
    toc-expand: true
    toc-title: Outline
    number-sections: true
    number-depth: 2
    section-titles: true
    keep_tex: true
    mainfontoptions:
      - Numbers = Proportional
header-includes:
  - \usepackage{mathtools}
  - \usepackage{graphicx}
  - \usepackage{subfig}
  - \usepackage{longtable}
  - \usepackage{booktabs}
  - \usepackage{makecell}
  - \usepackage{wrapfig}
  - \usepackage{rotating}
  - \usepackage[boxed,longend,linesnumbered]{algorithm2e}
  - \usepackage[normalem]{ulem}
  - \usepackage{amsmath}
  - \usepackage{amssymb}
  - \usepackage{capt-of}
  - \usepackage{hyperref}
  - \usepackage{tikz}
  - \usetikzlibrary{shapes.geometric, arrows}
  - \hypersetup{colorlinks=true, linkcolor=blue, filecolor=magenta, urlcolor=cyan, pdftitle={BEST ELC Primary Analysis Discussion}, pdfpagemode=FullScreen}
  - \usepackage[style=verbose,backend=biber,isbn=false,url=false,doi=false,eprint=false,dashed=false]{biblatex}
---

# Overview

```{r libs_and_scripts}
# Load necessary libraries
library(tidyverse)
library(kableExtra)
library(fabricatr)
library(ggplot2)
library(ggpattern)
library(beanplot)
library(svglite)
library(hrbrthemes)
library(ggpubr)
library(grid)
library(gridExtra)

# Set Default Chunk Options
knitr::opts_chunk$set(echo = FALSE)

# Define constants
seed_val <- 42

colorblind_palette  <- c("#999999", "#E69F00", "#56B4E9", "#009E73",
                         "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
                                        # Load source files
set.seed(seed_val)
source("../code/00_aesthetic_utils.R")
source("../code/01_gen_fake_data.R")
source("../code/02_plot_predictors.R")
source("../code/03_plot_value_comparisons.R")
source("../code/04_plot_dtr_assignments.R")
source("../code/05_plot_forest_subgroups.R")
source("../code/06_descriptive_plots.R")
source("../code/101_plot_beibo.R")
```


### Overview

#### Discussion Order

1. Recap of key points from past ELC discussions (check my understanding)
2. Analysis scientific overview
3. 12-week manuscript mock tables and figures
4. 24-week manuscript mock tables and figures
\vfill

#### Tables and Figures
The mock tables and figures for the 12- and 24-week manuscripts are formatted as
they might appear in the manuscripts\footnote{Numbers are entirely made up and
not based on preliminary data in any way.}.

\vfill

Standard components like the table of descriptive statistics and CONSORT flow
diagram are not included. Appendix contents are also not included except where
explicitly noted.

# Summary of Recent Discussions

## Publication and Communication Strategy Discussion

### Publication Strategy

Co-publish manuscripts for the 12- and 24-week outcomes.

\vfill
There is precedent e.g. the GRADE trial published two results papers in the same issue of the New England Journal of Medicine.

### Future Analyses
  - Additional protocol objectives: patient preferences, deep phenotyping,
    and the 36-week outcome.
   \vfill

  - Investigating ``nearly optimal'' treatment recommendations and predictors of
    response to treatment that are nearly as good as those in the primary
    analysis.
   \vfill

  - Consortium-wide data analyses and integration.

### Language Discussion

This will be the language used in internal ongoing discussions, the design, and the primary analysis manuscripts.
\vfill

Nonbinding; field and journal specific terms will take precedence for manuscripts.
\vfill
\begin{columns}
\begin{column}{0.5\textwidth}

Patient Features
\begin{itemize}
\item Biomarkers
\item  Phenotypes
\item  Phenotypic markers
\item  Patient characteristics
\item  Patient features


\end{itemize}
\end{column}
\hfill
\begin{column}{0.5\textwidth}

Dynamic Treatment Regime (DTR)
\begin{itemize}
\item  Individualized Treatment Rule
\item  Dynamic Treatment Regime
\item  Treatment policy
\item  Treatment recommendations
\item  Policy (in CS and OR)
\item  Automated clinical decision aid (this is not a one-to-one substitute)


\end{itemize}
\end{column}
\end{columns}

## Key Points from Previous Discussions

### Key Points

- The study treatments are representative of classes of treatments rather than
  fully optimized interventions.

- Variable importance measurements can be unstable.

Ex: Only one of anxiety and depression may be labeled as important depending on
  the metric, but having one rather than the other would likely only have a
  small impact\footnote{Setting aside negative affect, and feature construction
  generally.}.

- We need to appropriately communicate uncertainty which goes beyond choosing
  appropriate statistical methods. (Elaborated on next slide)

- The DTR is still the estimated optimal way to recommend treatments based on
  the data from the BEST trial.

### Key Discussion Points - Uncertainty Communication
\begin{itemize}
\item This is a complex analysis and is
  discovery-focused, need to preempt misinterpretation of results as certainties
  from the ``magic box'' of machine learning.
\vfill
Yes: If successful, a clinician could reasonably justify applying the DTR published
in the manuscript in their clinic. The trial provides valid evidence by virtue
of appropriately accounting for hypothesis-generation and modeling flexibility,
and treatments are all currently used in clinical practice and efficacious.

No: The trial provides conclusive evidence and no further research is needed to
confirm that the estimated DTR is optimal.

\vfill
\item Concerns that decision-lists and trees convey a high-level of certainty.
\vfill

\item There is no independent test data set (though we apply appropriate
statistical methods to account for the flexible modeling process).
\vfill

\end{itemize}

### Future Confirmatory Studies (Drop or move to appendix?)
A ``Phase III'' confirmatory trial which randomizes patients to receive
treatment according to the estimated DTR vs. receiving treatment by some
appropriate comparison method
\begin{itemize}
\item Clinical judgment without access to the DTR
\item Clinical judgment where the clinician has information about the treatment the DTR estimates is optimal and an explanation for the algorithm's decision.

\item Randomization
\end{itemize}

\vfill \pause
Similar trials happen in fields such as implementation science, but the
intervention packages aren't developed in as systematic a way as the DTR from
BEST.
\vfill

Aren't commonplace, but I (John) dream of a world where all treatment guidelines
are put through this kind of testing, and when your doctor recommends an
intervention to you, you can source the evidence for the
recommendation\footnote{Not just single trials or systematic reviews}.

# A Science-level View of the Analysis

## Fundamental Questions in Precision Medicine

### Fundamental Questions in Precision Medicine
\begin{itemize}
\item For a specific patient, what is the best treatment?
\vfill

\item For a specific treatment, what patient features are most important for
predicting treatment response?
\end{itemize}

### Why both "best patient" and "best treatment" analyses matter
```{r pmed_motivation_plot, fig.height = 3, fig.width = 7}
ThemePlot(CreateExDTRRespDifPlot())
```

The optimal treatment recommendation is "always give meditation" in this
example. Acupuncture gets less effective with age, while meditation gets more effective with age.

### Decision-support and Causal Prediction are complementary but distinct

Statistical recommendations are always in the context of a set of
options and aren't sufficient to know what predicts treatment response:
\begin{itemize}
\item Features can effect treatment efficacy but not to a sufficient
degree to change the reccommendation

\item A feature may predict treatment response for all treatment options and not
 distinguish who should receive what.
\end{itemize}

Knowing what features predict treatment response isn't enough to know
which treatment to recommend.

There is no age (in a human lifespan) where acupuncture should be recommended in
this example despite age reducing the effectiveness of meditation and increasing
the effectiveness of acupuncture.


## The Analysis in terms of Scientific Questions

### Analysis as Scientific Questions
\begin{enumerate}
\item What were the observed outcomes in the trial?
\vdots

\setcounter{enumi}{4}

\item How did each of the above differ for patients with and without contraindications?"
\end{enumerate}

\vfill

The ordering of the following three items could be changed and two options are
on the next slide.

\vfill
\begin{itemize}
\item What is the benefit of incorporating patient features?
\vfill

\item For a specific patient, what is the best treatment?
\vfill

\item For a specific treatment, what patient features predict response to
treatment?
\vfill
\end{itemize}

Each of these questions has at least one corresponding figure or table in the manuscript.

### Analysis Question Ordering

\vfill

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Sequential ordering}
\begin{enumerate}
\item For a specific treatment, what patient features predict response to
treatment?
\vfill

\item For a specific patient, what is the best treatment?
\vfill

\item What is the benefit of incorporating patient features?
\vfill

\end{enumerate}
\end{column}
\hfill
\begin{column}{0.5\textwidth}

\textbf{Headline ordering}
\begin{enumerate}
\item What is the benefit of incorporating patient features?
\vfill

\item For a specific patient, what is the best treatment?
\vfill

\item For a specific treatment, what patient features predict response to
treatment?
\vfill
\end{enumerate}
\end{column}
\end{columns}
\vfill


## Mapping Analyses to Scientific Questions

### Analysis as Scientific Questions Details

#### What were the observed outcomes in the trial?
\small
Descriptive summary of the as-randomized outcomes
\vfill \pause
#### For a specific treatment, what patient features predict response to treatment?
\small
\begin{itemize}
\item Addressed using variable importance plots for predictors of treatment
response.

\item No statistical inference for individual predictors.

\item Important for future research into new treatments and treatment mechanisms
as well as for identifying patients who are unlikely to have successful response to
any of the current treatment options.

\item Can inform clinical judgment and supplement the recommendation from the DTR.
\end{itemize}
\vfill

### Analysis as Scientific Questions Details

#### For a specific patient, what is the best treatment?

\begin{itemize}
\item Describe the DTR. For an interpretable DTR this can be directly communicated. Complex DTRs require a computer.

\vfill

\item What is the estimated impact of applying the DTR including the proportion of
patients assigned to each treatment and changes in treatment efficacy. Will includea basic algorithmic bias assessment in the appendix.
\vfill

\item Could discuss the expected improvement in PEG for subgroups of patients. The expected improvement in the population is the next question.
\end{itemize}

\vfill \pause
#### What is the benefit of incorporating patient features?

Hypothesis test of the value of the estimated optimal DTR compared to the
as-randomized outcomes.
\vfill \pause

### Contraindications

#### How did each of the above differ for patients with and without contraindications?
Participants with contraindications are included in the primary analyses.\footnote{With techniques such as weighting used to account for different randomization probabilities when there are restrictions.}
\vfill

Throughout the whole analysis could report: Overall, No contraindications,
with contraindications. This doesn't cost much space for any study-population-level summary, but could be an issue if the DTRs differ substantially by contraindication.

\vfill
For space reasons maybe a paragraph of text rather than the multiple
tables/figures?


# 12-week Paper

## Descriptive summary of trial results

```{r descriptive_data}
fake_stage_one_wide <- FakeDataDescriptiveAnalyses(n.subj = 804)
fake_stage_one_long <- TransformWideToLong(fake_stage_one_wide)
```
### 12-week Descriptive Outcomes Tables
\begin{columns}
\begin{column}{0.35\textwidth}
 \begin{minipage}{\linewidth}
\small
```{r simple_descriptive_table, results = 'asis'}
simple_results_tbl_df <- SummarizeDescriptiveOutcomes(fake_stage_one_long,
    include_fivenum = FALSE
) %>%
    mutate(PrintMeanSd = paste0(round(Mean, 1), " (", round(SD, 1), ")"))


simple_results_wide <- data.frame(
    Treatment = simple_results_tbl_df$Trt[1:4],
    PEG = simple_results_tbl_df[simple_results_tbl_df$Outcome == "PEG",]$PrintMeanSd,
    PGIC = simple_results_tbl_df[simple_results_tbl_df$Outcome == "PGIC",]$PrintMeanSd
)

# Create the LaTeX table
simple_latex_table <- simple_results_wide %>%
    kable(format = "latex",
          digits = 1,
          booktabs = TRUE,
          caption = "BEST Trial 12-week ITT Outcomes by Treatment Assignment") %>%
  kable_styling(latex_options = c("striped", "hold_position","scale_down" ))

# Print the LaTeX table
print(simple_latex_table)
```
\end{minipage}
\end{column}
\hfill
\begin{column}{0.65\textwidth}
\begin{minipage}{\linewidth}
\small
```{r descriptive_table, results = 'asis'}
results_tbl_df <- SummarizeDescriptiveOutcomes(fake_stage_one_long,
                                               include_fivenum = TRUE
)
# Create the LaTeX table
latex_table <- results_tbl_df %>%
    kable(format = "latex",
          digits = 1,
          booktabs = TRUE,
          caption = "BEST Trial 12-week ITT Outcomes by Treatment Assignment Descriptive Statistics") %>%
  kable_styling(latex_options = c("striped", "hold_position", "scale_down"))

# Print the LaTeX table
print(latex_table)
```
\end{minipage}
\end{column}
\end{columns}


### Bean plot of 12-week PEG with quantiles
\small
Bean plots are an alternative to box plots that show all of the observations
(the dots), and the probability density (the violin shapes) in addition to the
median and lower & upper quartiles.

```{r stageone_ggbean_peg_quantiles, fig.height = 2.5, fig.width = 5, fig.cap='BEST Trial 12-week ITT PEG by Treatment Assignment'}
ggbp_two <- GGBeanPlot(
    wide_data = fake_stage_one_wide,
    outcome_name = "PEG",
    violin_quantiles = c(.25, .5, .75)
)


ggbp_peg_themed <- ThemePlot(ggbp_two) + theme(panel.grid.minor = element_blank())
ggbp_peg_themed
```

### Bean plot of 12-week PGIC with quantiles

```{r stageone_ggbean_pgic_quantiles, fig.height = 3.5, fig.width = 7, fig.cap='BEST Trial 12-week PGIC by Treatment Assignment (ITT)'}
ggbp_pgic <- GGBeanPlot(
    wide_data = fake_stage_one_wide,
    outcome_name = "PGIC",
    violin_quantiles = c(.25, .5, .75)
)

ggbp_pgic_themed <- ThemePlot(ggbp_pgic) + theme(panel.grid.minor = element_blank())
ggbp_pgic_themed
```

### Bean plot of 12-week PEG and PGIC with quantiles

```{r stageone_ggbean_grid_quantiles, fig.height = 3.5, fig.width = 7, fig.cap='BEST Trial 12-week ITT Outcomes by Treatment Assignment'}
gridExtra::grid.arrange(ggbp_peg_themed, ggbp_pgic_themed, ncol = 2)
```

## Predictors of Treatment Response
### Predictor magnitude figure
```{r trt_pred, warning = FALSE, message = FALSE}
pred_summary_df <- FakeDataForPredictorSummary()
pubr_pred <- PlotPredPubr(in.data = pred_summary_df)
```

```{r pred_pubr, fig.height = 4, fig.width = 6, warning = FALSE, message = FALSE}
pubr_pred
```

### Variable Importance

```{r pred_beibo_importance, fig.height = 3, fig.width = 4, warning = FALSE, message = FALSE}
pred_summary_df <- FakeDataForPredictorSummary()
PlotVarImportance.BZ(pred_summary_df)
```


## What is the best treatment for each patient?

### DTR Description - Common Interpretable Model Forms
\begin{columns}
\begin{column}{0.5\textwidth}
\small
Integer Scoring Models

\begin{tabular}{@{}lll@{}}
\toprule
Characteristic      &  & Points \\ \midrule
                    &  &        \\
Age $\geq 65$       &  & +1     \\ \cmidrule(l){3-3}
Depression          &  & +3     \\ \cmidrule(l){3-3}
Duration $<5$ years &  & -2     \\ \cmidrule(l){3-3}
Current Opioid Use  &  & +4     \\ \cmidrule(l){3-3}
                    &  &        \\ \midrule
Total Score         &  &        \\ \bottomrule
\end{tabular}

\tiny Total Score: $< 1$ recommend ESC, 1-4 recommend Duloxetine, 7+ recommend ACT
\vfill
\end{column}
\hfill
\begin{column}{0.5\textwidth}
Tree-based methods
\includegraphics[width=0.8\textwidth]{old/figure/pain-decision-tree}
\end{column}
\end{columns}
\small
 Neither approach is universally superior: Trees often perform comparatively well in settings with many categorical features and higher-order interactions, and worse in settings with smooth, low-degree parametric relationships.

### Interpretable Modeling

Integer Scoring models and tree models can be forced to include multiple subscales where features belong to one subscale (e.g. PROs) which are then combined, or all features can be included in a single mdoel.


The approach is based on Generalized Additive Models (GAMs)

### Describing the DTR Recommendations
## Characterizing the Treatment Recommendations
Answers the question "What would following the treatment recommendations look
like in practice?" or "Who do the people who are recommended an intervention
look like?"

```{r results='asis'}
# Create the data frame
data <- tibble(
    `Treatment Assignment Strategy` =
        c("Study Assignments", "PEG DTR", "PGIC DTR"),
    Duloxetine = c("25%", "30%", "40%"),
    ACT = c("25%", "70%", "10%"),
    EBEM = c("25%", "0%", "40%"),
    ESC = c("25%", "0%", "10%"),
)

# Generate the table with enhanced aesthetic styling
knitr::kable(data, format = "latex",
          digits = 1,
align = "c",
          booktabs = TRUE) %>%
kable_styling(latex_options = "striped")
```



### Estimated Improvement within subgroups defined by the DTR
The features a DTR uses to recommend a treatment create a set of mutually distinct subgroups that encompass the entire patient population.
\vfill

```{r results='asis'}
# Create the data frame
data <- tibble(
    `Subgroup` =
        c("Short Pain Duration", "Low self-efficacy", "Elderly & Extremely Long Pain Duration"),
`Recommended Treatment` = c("EBEM", "ACT", "ESC"),
    `Expected Improvement(%)` = c("+40%", "+25%", "+0%")
)

# Generate the table with enhanced aesthetic styling
knitr::kable(data, format = "latex",
          digits = 1,
align = "c",
col.names = c("Subgroup", "Recommendation", "Expected Improvement"),
          booktabs = TRUE,
caption = "Expected Relative Improvement in 12-week PGIC by subgroup using the Estimated Optimal DTR compared to Randomized Assignment") %>%
kable_styling(latex_options = "striped")
```
\vfill

Important note: This is a comparison between different ways of recommending treatments (with the study randomization being one way to assign treatments).


\vfill

### Properties of Analyzing the DTR Subgroups
\begin{itemize}
\item Should have no or very small negative changes --- because these are the subgroups used to recommend a treatment, a negative change would imply that there's a better treatment for that subgroup, but that contradicts this being the estimated optimal DTR\footnote{Small negative values may be possible due to e.g. sample splitting}.

\item This is only guaranteed for the subgroups defined by the DTR.

Ex: If the estimated optimal DTR doesn't include current opioid use, there is no guarantee that

\item The optimality of the estimated DTR does suggest that you couldn't improve outcomes for a subgroup without reducing the benefit for other groups

\item Looking at single factors and holding everything else fixed can be misleading as patients have many correlated features.

\end{itemize}

### Stratifying Results by Treatment Assignment is Unwise in this Context (WORDSMITH)

``In the general population Duloxetine has a 30% success rate\footnote{ignoring that our outcomes aren't dichotomized}, but incorporating patient features it has a 50% success rate''

```{r results='asis'}
# Create the data frame
data <- tibble(
    `Outcome` =
        c("PEG", "PGIC"),
    Duloxetine = c("+50%", "+40%"),
    ACT = c("+5%", "-10%"),
    EBEM = c(NA, "+40%"),
    ESC = c(NA, "-10%")
)

# Generate the table with enhanced aesthetic styling
knitr::kable(data, format = "latex",
          digits = 1,
align = "c",
          booktabs = TRUE,
caption = "Expected Improvement in Outcome by Assigned Treatment for those Recommended Treatment compared to the Randomized Treatment Assignment") %>%
kable_styling(latex_options = "striped")
```

The population of patients assigned to a treatment under the DTR will differ from the general patient population.

### Stratifying by Treatment Assignment Continued
A treatment may be the best treatment for a subgroup, but if patients in that subgroup have worse outcomes than the general patient population the success rate for that treatment would decrease under the DTR.

\vfill

Can't fix both the treatment and the subgroup, the conditional outcomes are the same---the expected improvement under Duloxetine for an individual does not depend on whether they received Duloxetine because they were randomized to it or because we think it's the best  treatment for them.
\vfill

Can't just take the predicted best responders and ignore the rest of the study population
\vfill

The estimated optimal DTR assigns each patient to the treatment with the largest predicted improvement in outcome given the patient's features.

## What is the benefit of incorporating patient features?

### As-randomized Outcome Comparison

Answers the question "What's the benefit of incorporating patient
characteristics into clinical decision making?"

```{r val_comp, fig.height = 3, fig.width = 9, warning = FALSE, message = FALSE}
# Call the function with specified treatment policy names
policy_names <- c("Ensemble", "Following\nRecommended\nTreatments", "Personalize\nStage One Only", "Best Single\nTreatment", "As-randomized")
fake_val_data <- FakeDataForValueComparison(policy_names,
                                            point_estimates = c(.65, .6, .475, .4, .3),
                                            ci_half_widths = c(.15, .15, .15, .15, .1))

fake_val_min_comp <- fake_val_data %>%
    filter(TreatmentPolicy %in% c("Following\nRecommended\nTreatments", "As-randomized"))
val_plot_min <- PlotValueComparison(in.data = fake_val_min_comp) +
    ylab("Treatment Approach")

ThemePlot(val_plot_min) + coord_flip()
```

### Open Question: Adjusting for 12-week Comparisons

Protocol primary objctive does not involve the 12-week outcomes

Don't adjust for multiplicity

Don't adjust for multiplicity across the two manuscripts, adjust within the 12-week paper



#### Multiplicity Adjustment Strategies
(Prespecify we will) Only test 12-week if 24-week is significant

Apply a standard adjustment method e.g. Benjamini-Hochberg

### Open Questions (if adjusting for multiplicity)

#### False Discovery Rate (FDR) or Family-Wise Error Rate (FWER) Control

FDR is the proportion of false positives out of all rejected hypotheses

FWER is the probability of making at least one false positive rejection

FWER is stricter and implies FDR control

#### What $\alpha$-level


## Discussion of results for participants with contraindications
### Description of contraindicated populations for each treatment
### DTR assignments by contraindication
### Outcomes for those with contraindications

# 24-week Paper

## Descriptive summary of trial results

### Stage Two Treatment Assignments
```{r trt_two_assignments, fig.height = 3.5, fig.width = 9, warning = FALSE, message = FALSE}
dtr_assignments <- FakeDataForDTRAssignments()
PlotTreatSqn.BZ(dtr_assignments) %>% ThemePlot(.)
```

### As-randomized outcomes

## Model Descriptions
### Interpretable Method discussion
Listed for completeness, shouldn't require further discussion after the 12-week
##discussion

### Ensemble model input table
Table of included models
(Appendix material most likely)

### State the optimal DTR for 24-week PEG

### Describe the (counterfactual) DTR assignments in the study population
Under the DTR in this population what percentage of people do we expected to be
assigned to each treatment?

## What is the benefit of incorporating patient features?

### Value versus as-randomized outcomes (benefit at the population level)
Figure, expected value under DTR vs. as-randomized

Under this DTR what percentage of people do we expect to augment/maintain/switch?

How does this compare to study assignments and responder categories?

### Stratified by assigned treatment?
Requested by clinicians, but I donâ€™t think this makes sense without subgroups because the populations will be different in the as-randomized and assigned by DTR groups. Note: Might be a way to get at what they want to know, think about it more.

### Stratified by DTR subgroup (and treatment)
As-randomized vs. DTR subgroup outcome comparison

## Predictors of Treatment Response
### Predictor magnitude figure
Figure Variable importance metrics

## Discussion of results for 12-week and 24-week PEG
### Differences in optimal DTRs?
### Differences in predictors of treatment response?


## Discussion of results for participants with contraindications
### Description of contraindicated populations for each treatment
### DTR assignments by contraindication
### Outcomes for those with contraindications

# Statistical Methods
## Model Descriptions
### Interpretable Method discussion
Not a table or figure, but an open item

Trees don't seem as popular as expected

### Ensemble model input table
Table of included models
(Appendix material most likely)


